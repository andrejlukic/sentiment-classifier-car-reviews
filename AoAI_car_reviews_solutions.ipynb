{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "Since the Scikit library offers all required functionality out of the box with an additional benefit of being able to make use of the pipeline object my initial manual implementation was replaced with the Scikit pipeline reducing the code size considerably. Below is the an implementation of a simple Multinomial Naive Bayes classifier using built-in count vectorizer with added stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit here if the path to the CSV is different:\n",
    "CSV_PATH = \"data/car-reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import ssl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    \"\"\"Class adds stemming of english words to the CountVectorizer\"\"\"\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "class CarReviewsClassifier():\n",
    "\n",
    "    def __init__(self, fpath):\n",
    "        \n",
    "        # this is needed since NLTK stop words download is buggy\n",
    "        try:\n",
    "            _create_unverified_https_context = ssl._create_unverified_context\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            ssl._create_default_https_context = _create_unverified_https_context\n",
    "            \n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "        \n",
    "        # load the car reviews dataset\n",
    "        dataset = pd.read_csv(fpath)\n",
    "        print(\"Loaded {} car reviews\".format(dataset.shape[0]))\n",
    "        \n",
    "        # split the dataset into a training / test set \n",
    "        self.trainsetX, self.testsetX, self.trainsetY, self.testsetY = \\\n",
    "            train_test_split(dataset.Review, dataset.Sentiment, test_size=0.2)\n",
    "\n",
    "\n",
    "    def train_and_test(self):\n",
    "\n",
    "        vectorizer = StemmedCountVectorizer(analyzer=\"word\", stop_words='english', binary=True, lowercase=True)\n",
    "        classifier = MultinomialNB()\n",
    "\n",
    "        self.pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "\n",
    "        # Train\n",
    "        self.pipeline.fit(self.trainsetX, self.trainsetY)\n",
    "        \n",
    "        # Predict\n",
    "        predY = self.pipeline.predict(self.testsetX)\n",
    "        \n",
    "        # Here the score is accuracy for classification (TN + TP)/Total\n",
    "        print(\"\\nAccuracy {:.2f}\".format(self.pipeline.score(self.testsetX, self.testsetY)))\n",
    "        \n",
    "        # Return the confusion matrix\n",
    "        return confusion_matrix(self.testsetY, predY)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy (TP+TN)/(TP+TN+FP+FN) of the simple classifier is between 75% and 80% which is not too bad considering no hyper-parameter tuning at all at this point. The chosen count vectorizer was binary since it proved to show better results in the second part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andrejwork/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andrejwork/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1382 car reviews\n",
      "\n",
      "Accuracy 0.78\n",
      "\n",
      "True positives 121\n",
      "True negatives 95\n",
      "False positives 39\n",
      "False negatives 22\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  Run this cell to test the basic Multinomial Naive Bayes classifier\n",
    "#\n",
    "\n",
    "tn, fp, fn, tp = CarReviewsClassifier(CSV_PATH).train_and_test().ravel()\n",
    "\n",
    "print(\"\\nTrue positives\", tp)\n",
    "print(\"True negatives\", tn)\n",
    "print(\"False positives\", fp)\n",
    "print(\"False negatives\", fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - manualy implemented count vectorizer\n",
    "\n",
    "To better demonstrate all the steps required in the stage of preprocessing more clearly I also implemented the count vectorizer manually. There are some differences between my implementation and the Scikit implementation above:\n",
    "* out of curiosity I implemented numerical count for the word/stem\n",
    "* train/test split of the dataset is done using Pandas sample method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "class CarReviewsClassifierManualVectorizer():\n",
    "\n",
    "    def __init__(self):\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "    def remove_stop_words(self, word_list):\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        filtered = [w for w in word_list if not w in stop_words]\n",
    "        return filtered\n",
    "\n",
    "    def lower_case(self, word_list):\n",
    "        return [w.lower() for w in word_list]\n",
    "\n",
    "    def stem_words(self, list_of_words):\n",
    "        ps = nltk.stem.PorterStemmer()\n",
    "        stemmed = [ps.stem(w) for w in list_of_words]\n",
    "        return stemmed\n",
    "\n",
    "    \n",
    "    def generate_bow_faster(self, list_tokenized_reviews):\n",
    "        \"\"\"Generates bag of words\"\"\"\n",
    "        # This is 6.5x faster than the previous version\n",
    "        from collections import OrderedDict\n",
    "\n",
    "        bow = {}\n",
    "        for r in list_tokenized_reviews:\n",
    "            for w in r:\n",
    "                if w in bow:\n",
    "                    bow[w] += 1\n",
    "                else:\n",
    "                    bow[w] = 1\n",
    "        self.bow_ordered = OrderedDict(sorted(bow.items(), key=lambda t: t[0]))  \n",
    "        inx = 0        \n",
    "        for key in self.bow_ordered:\n",
    "            self.bow_ordered[key] = (inx, self.bow_ordered[key])\n",
    "            inx += 1\n",
    "    \n",
    "    def parse_sentiment(self, s):\n",
    "        if s.lower() == 'neg':\n",
    "            return 0\n",
    "        elif s.lower() == 'pos':\n",
    "            return 1\n",
    "        else:\n",
    "            print(s)\n",
    "            raise\n",
    "    \n",
    "    def count_vectorize(self, df, test=False):\n",
    "        list_tokenized_reviews = []\n",
    "        sentiments = []\n",
    "        for r, sent in zip(df[\"Review\"].to_list(), df[\"Sentiment\"].to_list()):\n",
    "            v = self.tokenize(r)\n",
    "            c = self.remove_stop_words(v)\n",
    "            l = self.lower_case(c)\n",
    "            s = self.stem_words(l)\n",
    "            list_tokenized_reviews.append(s)\n",
    "            sentiments.append(self.parse_sentiment(sent))\n",
    "\n",
    "        if not test:\n",
    "            # Generate bag of words for train dataset\n",
    "            self.generate_bow_faster(list_tokenized_reviews)\n",
    "        \n",
    "        list_features = []\n",
    "        for review in list_tokenized_reviews:\n",
    "            vector = [0] * len(self.bow_ordered)\n",
    "            for i in range(len(review)):\n",
    "                if review[i] in self.bow_ordered:\n",
    "                    inx = self.bow_ordered[review[i]][0]\n",
    "                vector[inx] += 1\n",
    "            list_features.append(vector)\n",
    "            \n",
    "        return list_features, sentiments\n",
    "\n",
    "    def train_and_test(self):\n",
    "        dataset = pd.read_csv(CSV_PATH)\n",
    "        print(\"Loaded {} car reviews\".format(dataset.shape[0]))\n",
    "        trainset = dataset.sample(int(0.8*dataset.shape[0]))\n",
    "        print(\"Chosing random {} reviews for training\".format(trainset.shape[0]))\n",
    "        testset = dataset.drop(trainset.index)\n",
    "        print(\"Testing on remaining {} reviews\".format(testset.shape[0]))\n",
    "        trainX, trainY = self.count_vectorize(trainset)\n",
    "\n",
    "        classifier = MultinomialNB()\n",
    "\n",
    "        # Train\n",
    "        classifier.fit(trainX, trainY)\n",
    "        \n",
    "        # Predict\n",
    "        testX, testY = self.count_vectorize(testset, test=True)\n",
    "        predY = classifier.predict(testX)\n",
    "        \n",
    "        # Here the score is accuracy for classification (TN + TP)/Total\n",
    "        print(\"\\nAccuracy {:.2f}\".format(classifier.score(testX, testY)))\n",
    "        \n",
    "        # Return the confusion matrix\n",
    "        return confusion_matrix(testY, predY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy (TP+TN)/(TP+TN+FP+FN) of this classifier with my custom implemented vectorizer is slighlty worse due to using count of word stems instead of binary values in the BOW. In later tests this approach proved to be consistently worse performing, but I added it here for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andrejwork/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andrejwork/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1382 car reviews\n",
      "Chosing random 1105 reviews for training\n",
      "Testing on remaining 277 reviews\n",
      "\n",
      "Accuracy 0.81\n",
      "\n",
      "True positives 121\n",
      "True negatives 102\n",
      "False positives 29\n",
      "False negatives 25\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  Run this cell to test the basic Multinomial Naive Bayes classifier with the manually implemented count vectorizer\n",
    "#\n",
    "\n",
    "tn, fp, fn, tp = CarReviewsClassifierManualVectorizer().train_and_test().ravel()\n",
    "\n",
    "print(\"\\nTrue positives\", tp)\n",
    "print(\"True negatives\", tn)\n",
    "print(\"False positives\", fp)\n",
    "print(\"False negatives\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - improving the classifier\n",
    "\n",
    "To improve my basic Multinomial Naive Bayes classifier the following steps were taken:\n",
    "\n",
    "1. comparison of multiple available classifiers using grid search and 5-fold cross validation\n",
    "2. hyper-parameter tuning of the best model\n",
    "\n",
    "The methods and process used are described in the cells bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import ssl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "class CarReviewsBetterClassifier():\n",
    "\n",
    "    def __init__(self, fpath):\n",
    "\n",
    "        try:\n",
    "            _create_unverified_https_context = ssl._create_unverified_context\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            ssl._create_default_https_context = _create_unverified_https_context\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "\n",
    "        dataset = pd.read_csv(fpath)\n",
    "        print(\"Loaded {} car reviews\".format(dataset.shape[0]))\n",
    "        self.trainsetX, self.testsetX, self.trainsetY, self.testsetY = \\\n",
    "            train_test_split(dataset.Review, dataset.Sentiment, test_size=0.2)\n",
    "                             #, random_state=44)\n",
    "\n",
    "\n",
    "    def train_and_test(self, min_df=2, max_df=1.0, ngram_range=(1,2), binary=True):\n",
    "        \"\"\"Using SVM and optimal values for the hyper-parameters\"\"\"\n",
    "\n",
    "        count_vect = StemmedTfidfVectorizer(analyzer=\"word\", stop_words='english', min_df=min_df, max_df=max_df, ngram_range=ngram_range, binary=binary, lowercase=True)\n",
    "        classifier = LinearSVC()\n",
    "\n",
    "        self.pipeline = Pipeline([\n",
    "            ('vectorizer', count_vect),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "\n",
    "        # call fit as you would on any classifier\n",
    "        self.pipeline.fit(self.trainsetX, self.trainsetY)\n",
    "\n",
    "        # predict test instances\n",
    "        predY = self.pipeline.predict(self.testsetX)\n",
    "        \n",
    "        print(\"\\nAccuracy {:.2f}\".format(self.pipeline.score(self.testsetX, self.testsetY)))\n",
    "        \n",
    "        return confusion_matrix(self.testsetY, predY)\n",
    "\n",
    "    def grid_search_vectorizer_params(self):\n",
    "        \"\"\"Hyper-parameter grid search\"\"\"\n",
    "\n",
    "        classifier = LinearSVC()\n",
    "        count_vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "        self.pipeline = Pipeline([\n",
    "            ('vectorizer', count_vect),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "\n",
    "        print(self.pipeline.get_params().keys())\n",
    "\n",
    "        parameters = [{\n",
    "            'classifier': (LinearSVC(),),\n",
    "            # 'classifier__alpha': (0.9,),\n",
    "            'vectorizer__binary': (True,),\n",
    "            'vectorizer__lowercase': (True,),\n",
    "            'vectorizer__max_df': (1.0,),\n",
    "            'vectorizer__min_df': (1, 3),\n",
    "            'vectorizer__ngram_range': ((1,2),(1,1)),\n",
    "            'vectorizer': (StemmedTfidfVectorizer(), StemmedCountVectorizer())\n",
    "        }]\n",
    "\n",
    "        grid_search = GridSearchCV(self.pipeline, parameters, verbose = 3, n_jobs = -1)\n",
    "        clf = grid_search.fit(self.trainsetX, self.trainsetY)\n",
    "        score = clf.score(self.testsetX, self.testsetY)\n",
    "        print(\"{} score: {}\".format(\"Classifier\", score))\n",
    "        print(\"Best params\", clf.best_params_)\n",
    "        print(\"Best estimator\", clf.best_estimator_)\n",
    "\n",
    "    def grid_search_classifier(self):\n",
    "        \"\"\"Optimal classifier grid search\"\"\"\n",
    "\n",
    "        classifier = LinearSVC()\n",
    "        count_vect = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "        self.pipeline = Pipeline([\n",
    "            ('vectorizer', count_vect),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "\n",
    "        print(self.pipeline.get_params().keys())\n",
    "\n",
    "        parameters = [{\n",
    "            'classifier': (MultinomialNB(), LinearSVC(), LogisticRegression(), RandomForestClassifier(), MLPClassifier()),\n",
    "            'vectorizer__binary': (True,),\n",
    "            'vectorizer__lowercase': (True,),\n",
    "            'vectorizer__max_df': (1.0,),\n",
    "            'vectorizer__min_df': (2,),\n",
    "            'vectorizer__ngram_range': ((1,2),),\n",
    "            'vectorizer': (StemmedTfidfVectorizer(),)\n",
    "        }]\n",
    "\n",
    "        grid_search = GridSearchCV(self.pipeline, parameters, verbose = 3, n_jobs = -1)\n",
    "        clf = grid_search.fit(self.trainsetX, self.trainsetY)\n",
    "        score = clf.score(self.testsetX, self.testsetY)\n",
    "        print(\"{} score: {}\".format(\"NB\", score))\n",
    "        print(\"Best params\", clf.best_params_)\n",
    "        print(\"Best estimator\", clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chosing the optimal classifier\n",
    "\n",
    "To compare different classifiers a grid search was used (above in the code method name: grid_search_classifier) and the following models were compared:\n",
    "\n",
    "* Multinomial Naive Bayes\n",
    "* Linear Support Vector\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "* Multi-layer Perceptron (here only default settings were tried!)\n",
    "\n",
    "A Scikit grid search GridSearchCV was used to run different classifiers and then the classifier with the highest accuracy score was chosen. In the cell bellow the grid search for the optimal classifier can be repeated, however beware it can take a longer time to run, especially since the Multi-Layered Perceptron is also among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# WARNING: this can take a longer time!\n",
    "#\n",
    "\n",
    "# Uncomment and run the line below to run a grid search of the aforementioned models:\n",
    "#CarReviewsBetterClassifier(CSV_PATH).grid_search_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning parameters\n",
    "\n",
    "Once the Support Vector Machine was determined as the best classifier for the task the grid search was repeated for the various parameters of the vectorizer (below in the code method name: grid_search_vectorizer_params):\n",
    "\n",
    "* vectorizer__binary - Using binary values vs count of word stems\n",
    "* vectorizer__max_df - removing terms that appear too frequently (expressed in percentage of the documents)          * vectorizer__min_df - removing terms that are too infrequent\n",
    "* vectorizer__ngram_range' - usig multi-word phrases instead of individual words\n",
    "* vectorizer - comparing various vectorizers:\n",
    "    * StemmedCountVectorizer - CountVectorizer with stemming added\n",
    "    * CountVectorizer - default CountVectorizer\n",
    "    * StemmedTfidfVectorizer  - term frequency–inverse document frequency with stemming added\n",
    "    * TfidfVectorizer - default term frequency–inverse document frequency\n",
    "    \n",
    "The tuning process required several refinement steps to keep the search grid small enough. Some other parameters were experimented with as well but are removed here for clarity purposes since they did not prove to have any considerable effect.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# WARNING: this can take a longer time!\n",
    "\n",
    "# Uncomment and run the line below to run a grid search of the aforementioned parameters:\n",
    "#CarReviewsBetterClassifier(CSV_PATH).grid_search_vectorizer_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "The Multinomial Naive Bayes proved to be slightly worse performing than the Support Vector Machine classifier. With optimal parameters the LinearSVM model consistently tested with accuracy between 0.8 and 0.86. The vectorizer that proved to be most successful was the term frequency–inverse document frequency vectorizer with added stemming (using the improved SnowballStemmer). Using unigrams and bigrams outperformed all other tested n-gram combinations and using binary values vs count of word stems consistently showed to be the better choice (even with Naive Bayes). Removing terms that were only present in one document also improved results slightly. Many other parameters were modified (like maximum number of features, alpha value, etc. but they did not show a measureable effect on the results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andrejwork/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andrejwork/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1382 car reviews\n",
      "\n",
      "Accuracy 0.82\n",
      "\n",
      "True positives 114\n",
      "True negatives 113\n",
      "False positives 26\n",
      "False negatives 24\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  Run this cell to run the final SVM classifier with optimal parameters:\n",
    "#\n",
    "tn, fp, fn, tp = CarReviewsBetterClassifier(CSV_PATH).train_and_test().ravel()\n",
    "\n",
    "print(\"\\nTrue positives\", tp)\n",
    "print(\"True negatives\", tn)\n",
    "print(\"False positives\", fp)\n",
    "print(\"False negatives\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
